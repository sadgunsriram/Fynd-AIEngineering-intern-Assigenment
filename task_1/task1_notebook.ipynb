{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27387e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Using cached google_api_python_client-2.187.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in d:\\users\\delll\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\delll\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Collecting typing-extensions (from google-generativeai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Using cached google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Using cached google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n",
      "Using cached google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Using cached httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: uritemplate, typing-extensions, rsa, protobuf, httplib2, proto-plus, grpcio, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.187.0 google-auth-2.43.0 google-auth-httplib2-0.2.1 google-generativeai-0.8.5 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 rsa-4.9.1 typing-extensions-4.15.0 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67895ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "       \n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyB5h_IhiTedRz2gaXxzik0oEKOixKnWOc4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64a4bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  We got here around midnight last Friday... the...      4\n",
       "1  Brought a friend from Louisiana here.  She say...      5\n",
       "2  Every friday, my dad and I eat here. We order ...      3\n",
       "3  My husband and I were really, really disappoin...      1\n",
       "4  Love this place!  Was in phoenix 3 weeks for w...      5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\delll\\Downloads\\yelp.csv\")\n",
    "\n",
    "df = df[[\"text\", \"stars\"]].dropna()\n",
    "df[\"stars\"] = df[\"stars\"].astype(int)\n",
    "\n",
    "df_sample = df.sample(200, random_state=42).reset_index(drop=True)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b499df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_V1 = \"\"\"\n",
    "You are a simple review classifier.\n",
    "\n",
    "Task:\n",
    "Given a Yelp-style customer review, classify its star rating from 1 to 5:\n",
    "1 = very bad\n",
    "2 = bad\n",
    "3 = neutral / mixed\n",
    "4 = good\n",
    "5 = excellent\n",
    "\n",
    "Return ONLY a JSON object with this exact schema:\n",
    "{{\n",
    "  \"predicted_stars\": <integer from 1 to 5>,\n",
    "  \"explanation\": \"<short explanation>\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12637ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_V2 = \"\"\"\n",
    "You are an expert sentiment analyst for a restaurant review platform.\n",
    "\n",
    "Read the following review and reason step by step about each aspect:\n",
    "- Food quality\n",
    "- Service quality\n",
    "- Ambience\n",
    "- Price/value\n",
    "- Overall tone (positive / neutral / negative)\n",
    "\n",
    "Then assign a star rating from 1 to 5 using these rules:\n",
    "1 = strongly negative, major issues\n",
    "2 = negative, clear dissatisfaction\n",
    "3 = mixed or neutral, as many positives as negatives\n",
    "4 = positive with minor complaints\n",
    "5 = strongly positive, very satisfied\n",
    "\n",
    "Return ONLY a valid JSON object with this exact schema:\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<one or two sentences explaining the rating>\"\n",
    "}}\n",
    "\n",
    "Do NOT include any extra text before or after the JSON. No markdown.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67462f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_V3 = \"\"\"\n",
    "You are a reliable, production-grade rating engine for Yelp-style reviews.\n",
    "\n",
    "Your output will be consumed by an automated system, so you MUST:\n",
    "- Always return STRICTLY valid JSON\n",
    "- Use the exact field names: \"predicted_stars\" and \"explanation\"\n",
    "- Return only one JSON object and nothing else.\n",
    "\n",
    "Rating guidelines:\n",
    "1 = very bad experience, mostly negative\n",
    "2 = bad experience, more negatives than positives\n",
    "3 = mixed/average, balanced positives and negatives\n",
    "4 = good experience with minor issues\n",
    "5 = excellent experience, strongly positive\n",
    "\n",
    "Examples:\n",
    "\n",
    "Review: \"Terrible service and the food was cold.\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 1,\n",
    "  \"explanation\": \"The customer is very unhappy with both food and service.\"\n",
    "}}\n",
    "\n",
    "Review: \"Great food and friendly staff, but the wait time was a bit long.\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 4,\n",
    "  \"explanation\": \"Overall positive experience with a small complaint about waiting.\"\n",
    "}}\n",
    "\n",
    "Now classify the following review. Use the same JSON format.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d19932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str) -> str:\n",
    "    \"\"\"Send prompt to chosen LLM provider and return raw text.\"\"\"\n",
    "    if USE_OPENAI:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "    else:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        resp = model.generate_content(prompt)\n",
    "        return resp.text\n",
    "\n",
    "JSON_RE = re.compile(r\"\\{.*\\}\", re.DOTALL)\n",
    "\n",
    "def extract_json(text: str):\n",
    "    \"\"\"Try to extract valid JSON object from model output.\"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "    # Try to find {...}\n",
    "    match = JSON_RE.search(text)\n",
    "    candidate = match.group(0) if match else text.strip()\n",
    "    try:\n",
    "        obj = json.loads(candidate)\n",
    "        return obj\n",
    "    except Exception:\n",
    "        # attempt simple fixes\n",
    "        candidate = candidate.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        try:\n",
    "            obj = json.loads(candidate)\n",
    "            return obj\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "def safe_predict(review_text: str, prompt_template: str, max_retries: int = 2):\n",
    "    \"\"\"Call LLM and always return (predicted_stars or None, explanation or '')\"\"\"\n",
    "    for attempt in range(max_retries + 1):\n",
    "        raw = call_llm(prompt_template.format(review_text=review_text))\n",
    "        data = extract_json(raw)\n",
    "        if data and \"predicted_stars\" in data:\n",
    "            try:\n",
    "                rating = int(data[\"predicted_stars\"])\n",
    "                if 1 <= rating <= 5:\n",
    "                    explanation = str(data.get(\"explanation\", \"\")).strip()\n",
    "                    return rating, explanation, True\n",
    "            except Exception:\n",
    "                pass\n",
    "        # backoff a bit\n",
    "        time.sleep(0.3 + 0.2 * attempt)\n",
    "    return None, \"\", False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d97673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(df, prompt_template, label: str):\n",
    "    preds = []\n",
    "    exps = []\n",
    "    valids = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        true_label = int(row[\"stars\"])\n",
    "        pred, explanation, valid_json = safe_predict(row[\"text\"], prompt_template)\n",
    "        preds.append(pred)\n",
    "        exps.append(explanation)\n",
    "        valids.append(valid_json)\n",
    "\n",
    "        # Optional: light progress print\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"{label}: processed {i+1}/{len(df)}\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "    result_df[f\"{label}_pred\"] = preds\n",
    "    result_df[f\"{label}_exp\"] = exps\n",
    "    result_df[f\"{label}_valid_json\"] = valids\n",
    "\n",
    "    # Filter out None predictions for accuracy\n",
    "    mask = result_df[f\"{label}_pred\"].notnull()\n",
    "    acc = accuracy_score(result_df.loc[mask, \"stars\"], result_df.loc[mask, f\"{label}_pred\"])\n",
    "    json_valid_rate = np.mean(result_df[f\"{label}_valid_json\"])\n",
    "\n",
    "    print(f\"\\n=== {label} RESULTS ===\")\n",
    "    print(f\"Accuracy (on valid preds): {acc:.3f}\")\n",
    "    print(f\"JSON validity rate:        {json_valid_rate:.3f}\")\n",
    "    print()\n",
    "\n",
    "    return result_df, acc, json_valid_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17d182f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: processed 20/200\n",
      "v1: processed 40/200\n",
      "v1: processed 60/200\n",
      "v1: processed 80/200\n",
      "v1: processed 100/200\n",
      "v1: processed 120/200\n",
      "v1: processed 140/200\n",
      "v1: processed 160/200\n",
      "v1: processed 180/200\n",
      "v1: processed 200/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== v1 RESULTS ===\n",
      "Accuracy (on valid preds): nan\n",
      "JSON validity rate:        0.000\n",
      "\n",
      "v2: processed 20/200\n",
      "v2: processed 40/200\n",
      "v2: processed 60/200\n",
      "v2: processed 80/200\n",
      "v2: processed 100/200\n",
      "v2: processed 120/200\n",
      "v2: processed 140/200\n",
      "v2: processed 160/200\n",
      "v2: processed 180/200\n",
      "v2: processed 200/200\n",
      "\n",
      "=== v2 RESULTS ===\n",
      "Accuracy (on valid preds): nan\n",
      "JSON validity rate:        0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3: processed 20/200\n",
      "v3: processed 40/200\n",
      "v3: processed 60/200\n",
      "v3: processed 80/200\n",
      "v3: processed 100/200\n",
      "v3: processed 120/200\n",
      "v3: processed 140/200\n",
      "v3: processed 160/200\n",
      "v3: processed 180/200\n",
      "v3: processed 200/200\n",
      "\n",
      "=== v3 RESULTS ===\n",
      "Accuracy (on valid preds): nan\n",
      "JSON validity rate:        0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "d:\\Users\\delll\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "v1_df, v1_acc, v1_json = run_experiment(df_sample, PROMPT_V1, \"v1\")\n",
    "v2_df, v2_acc, v2_json = run_experiment(df_sample, PROMPT_V2, \"v2\")\n",
    "v3_df, v3_acc, v3_json = run_experiment(df_sample, PROMPT_V3, \"v3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06cf2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "USE_OPENAI = False\n",
    "USE_GEMINI = True\n",
    "\n",
    "def call_llm(prompt):\n",
    "    if USE_OPENAI:   \n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98de0d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>JSON_Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1 (baseline)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V2 (structured)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V3 (few-shot + strict)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Prompt  Accuracy  JSON_Validity\n",
       "0           V1 (baseline)       NaN            0.0\n",
       "1         V2 (structured)       NaN            0.0\n",
       "2  V3 (few-shot + strict)       NaN            0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame([\n",
    "    {\"Prompt\": \"V1 (baseline)\", \"Accuracy\": v1_acc, \"JSON_Validity\": v1_json},\n",
    "    {\"Prompt\": \"V2 (structured)\", \"Accuracy\": v2_acc, \"JSON_Validity\": v2_json},\n",
    "    {\"Prompt\": \"V3 (few-shot + strict)\", \"Accuracy\": v3_acc, \"JSON_Validity\": v3_json},\n",
    "])\n",
    "comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
